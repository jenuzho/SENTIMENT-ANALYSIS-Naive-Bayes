{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "\n",
                "<br>\n",
                "\n",
                "<br>\n",
                "\n",
                "# ðŸ’• **SENTIMENT ANALYSIS** ðŸ’•"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**NAIVE BAYES**\n",
                "-  **GaussianNB**\n",
                "- **MultinomialNB**\n",
                "- **BernoulliNB**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "\n",
                "## **INDEX**\n",
                "\n",
                "- **STEP 1: PROBLEM DEFINITION AND DATA COLLECTION**\n",
                "- **STEP 2: STUDY OF VARIABLES AND PROCESSING**\n",
                "- **STEP 3: MODEL SELECTION**\n",
                "- **STEP 4: OPTIMIZE THE MODEL WITH RANDOM FOREST**\n",
                "- **STEP 5: SAVE THE MODEL**\n",
                "- **STEP 6: STEP 6: EXPLORE ALTERNATIVE MODELS**\n",
                "- **STEP 7: CONCLUSION**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "\n",
                "## **STEP 1: PROBLEM DEFINITION AND DATA COLLECTION**\n",
                "\n",
                "- 1.1. Problem Definition\n",
                "- 1.2. Library Importing\n",
                "- 1.3. Loading Dataset"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "\n",
                "**1.1. PROBLEM DEFINITION**\n",
                "\n",
                "\n",
                "The goal of this project is to develop a **Sentiment Analysis Classifier** for Google Play Store reviews using **Naive Bayes Models**. This classifier will determine whether a review has a **positive** (`1`) or **negative** (`0`) polarity based on its textual content.\n",
                "\n",
                "<br>\n",
                "\n",
                "**WHAT IS SENTIMENT ANALYSIS?**\n",
                "\n",
                "Sentiment analysis is a process in **Natural Language Processing (NLP)** used to identify and classify the sentiment of text data into categories such as **positive**, **negative**, or **neutral**. It is widely used in business and research to understand user feedback, gauge customer satisfaction, and monitor public opinion.\n",
                "\n",
                "<br>\n",
                "\n",
                "**NAIVE BAYES MODELS**\n",
                "\n",
                "Naive Bayes is a family of **Probabilistic Classification Algorithms** based on **Bayes' Theorem**. It assumes independence among predictors, making it highly efficient for text classification tasks like sentiment analysis. \n",
                "\n",
                "**Types of Naive Bayes Models**\n",
                "1. **GaussianNB**: Assumes features follow a normal distribution.\n",
                "2. **MultinomialNB**: Suitable for discrete features, like word counts.\n",
                "3. **BernoulliNB**: Designed for binary/boolean features.\n",
                "\n",
                "In this project, these models will be applied to classify **Google Play Store reviews**, with a focus on identifying the most appropriate Naive Bayes implementation for the problem.\n",
                "\n",
                "<br>\n",
                "\n",
                "**VARIABLES**\n",
                "- **`review` (Predictor)**: The text of the userâ€™s comment, which will be processed into numerical features.\n",
                "- **`polarity` (Target)**: The sentiment of the comment, either **0** (negative) or **1** (positive).\n",
                "\n",
                "<br>\n",
                "\n",
                "**KEY STEPS**\n",
                "1. **Text Preprocessing**: Cleaning and converting text into a numerical format using techniques like removing spaces, converting to lowercase, and vectorization with **CountVectorizer**.\n",
                "2. **Model Selection**: Comparing and evaluating **GaussianNB**, **MultinomialNB**, and **BernoulliNB** to identify the best-performing model.\n",
                "3. **Model Optimization**: Enhancing the chosen model with additional algorithms, such as **Random Forest**.\n",
                "4. **Model Deployment**: Saving the trained model for future use.\n",
                "\n",
                "<br>\n",
                "\n",
                "**CHARACTERISTICS OF THE PROBLEM**\n",
                "- The dataset is **imbalanced**, containing textual data with **dichotomous labels**.\n",
                "- The primary predictor, `review`, needs **NLP preprocessing** before modeling.\n",
                "- The solution requires not only classification but also model **optimization** for better performance.\n",
                "\n",
                "<br>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "\n",
                "**1.2. LIBRARY IMPORTING**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import accuracy_score, classification_report\n",
                "import pickle\n",
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "\n",
                "**1.3. LOADING THE DATASET**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>package_name</th>\n",
                            "      <th>review</th>\n",
                            "      <th>polarity</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>privacy at least put some option appear offli...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>messenger issues ever since the last update, ...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>profile any time my wife or anybody has more ...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>the new features suck for those of us who don...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>forced reload on uploading pic on replying co...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "          package_name                                             review  \\\n",
                            "0  com.facebook.katana   privacy at least put some option appear offli...   \n",
                            "1  com.facebook.katana   messenger issues ever since the last update, ...   \n",
                            "2  com.facebook.katana   profile any time my wife or anybody has more ...   \n",
                            "3  com.facebook.katana   the new features suck for those of us who don...   \n",
                            "4  com.facebook.katana   forced reload on uploading pic on replying co...   \n",
                            "\n",
                            "   polarity  \n",
                            "0         0  \n",
                            "1         0  \n",
                            "2         0  \n",
                            "3         0  \n",
                            "4         0  "
                        ]
                    },
                    "execution_count": 37,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df = pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/naive-bayes-project-tutorial/main/playstore_reviews.csv\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "\n",
                "## **STEP 2: STUDY OF VARIABLES AND PROCESSING**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- 2.1. Focus on relevant variables\n",
                "- 2.2. Preprocess the text\n",
                "- 2.3. Split the data into Training and Testing sets\n",
                "- 2.4. Vectorize Text Data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In this step, we are preparing the dataset for modeling.\n",
                "\n",
                "<br>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "\n",
                "**2.1. FOCUS ON RELEVANT VARIABLES**\n",
                "\n",
                "Remove the **`package_name`** column since it doesn't contribute to classifying the sentiment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>review</th>\n",
                            "      <th>polarity</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>privacy at least put some option appear offli...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>messenger issues ever since the last update, ...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>profile any time my wife or anybody has more ...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>the new features suck for those of us who don...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>forced reload on uploading pic on replying co...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                              review  polarity\n",
                            "0   privacy at least put some option appear offli...         0\n",
                            "1   messenger issues ever since the last update, ...         0\n",
                            "2   profile any time my wife or anybody has more ...         0\n",
                            "3   the new features suck for those of us who don...         0\n",
                            "4   forced reload on uploading pic on replying co...         0"
                        ]
                    },
                    "execution_count": 38,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Dropping the irrelevant column\n",
                "df = df.drop(columns=['package_name'])\n",
                "\n",
                "# Display the updated structure of the dataset\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "\n",
                "**2.2. PREPOCESS THE TEXT**\n",
                "\n",
                "Clean and normalize the text in the **`review`** column by removing spaces and converting all text to lowercase."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0    privacy at least put some option appear offlin...\n",
                            "1    messenger issues ever since the last update, i...\n",
                            "2    profile any time my wife or anybody has more t...\n",
                            "3    the new features suck for those of us who don'...\n",
                            "4    forced reload on uploading pic on replying com...\n",
                            "Name: review, dtype: object"
                        ]
                    },
                    "execution_count": 39,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Cleaning and normalizing text\n",
                "df['review'] = df['review'].str.strip().str.lower()\n",
                "\n",
                "# Display a few cleaned reviews\n",
                "df['review'].head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "\n",
                "**2.3. SPLIT THE DATA INTO TRAINING AND TESTING SETS**\n",
                "\n",
                "Divide the dataset into **TRAINING** and **TESTING** subsets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define predictors (X) and target (y)\n",
                "X = df['review']\n",
                "y = df['polarity']\n",
                "\n",
                "# Splitting data into training and testing sets\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "\n",
                "**2.4. VECTORIZE TEXT DATA**\n",
                "\n",
                "Convert the cleaned text into a numerical format using **CountVectorizer**, which creates a matrix of word counts, ignoring common stop words."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize the CountVectorizer\n",
                "vec_model = CountVectorizer(stop_words=\"english\")\n",
                "\n",
                "# Fit and transform the training data\n",
                "X_train = vec_model.fit_transform(X_train).toarray()\n",
                "\n",
                "# Transform the testing data using the same vectorizer\n",
                "X_test = vec_model.transform(X_test).toarray()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "\n",
                "<br>\n",
                "\n",
                "## **STEP 3: MODEL SELECTION**\n",
                "\n",
                "- 3.1. Train and evaluate models using training and testing datasets.\n",
                "- 3.2. Compare the models' performance to determine the most suitable one for this problem.\n",
                "\n",
                "<br>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "\n",
                "**3.1. TRAIN AND EVALUATE MODELS USING TRAINING AND TESTING DATASETS**\n",
                "\n",
                "- Train the models using the training dataset.\n",
                "- Evaluate their performance by testing them on the testing dataset using appropriate metrics (e.g., `accuracy`, `precision`, `recall`, or `F1-score`)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "- **Train BernoulliNB**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "BernoulliNB Accuracy: 0.770949720670391\n",
                        "Classification Report for BernoulliNB:\n",
                        "               precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.79      0.93      0.85       126\n",
                        "           1       0.70      0.40      0.51        53\n",
                        "\n",
                        "    accuracy                           0.77       179\n",
                        "   macro avg       0.74      0.66      0.68       179\n",
                        "weighted avg       0.76      0.77      0.75       179\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Initialize the BernoulliNB model\n",
                "bernoulli_nb = BernoulliNB()\n",
                "\n",
                "# Train the model\n",
                "bernoulli_nb.fit(X_train, y_train)\n",
                "\n",
                "# Make predictions\n",
                "y_pred_bernoulli = bernoulli_nb.predict(X_test)\n",
                "\n",
                "# Evaluate the model\n",
                "print(\"BernoulliNB Accuracy:\", accuracy_score(y_test, y_pred_bernoulli))\n",
                "print(\"Classification Report for BernoulliNB:\\n\", classification_report(y_test, y_pred_bernoulli))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "\n",
                "- **Train GaussianNB**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "GaussianNB Accuracy: 0.8044692737430168\n",
                        "Classification Report for GaussianNB:\n",
                        "               precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.85      0.88      0.86       126\n",
                        "           1       0.69      0.62      0.65        53\n",
                        "\n",
                        "    accuracy                           0.80       179\n",
                        "   macro avg       0.77      0.75      0.76       179\n",
                        "weighted avg       0.80      0.80      0.80       179\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Initialize the GaussianNB model\n",
                "gaussian_nb = GaussianNB()\n",
                "\n",
                "# Train the model (requires dense array for GaussianNB)\n",
                "gaussian_nb.fit(X_train, y_train)\n",
                "\n",
                "# Make predictions\n",
                "y_pred_gaussian = gaussian_nb.predict(X_test)\n",
                "\n",
                "# Evaluate the model\n",
                "print(\"GaussianNB Accuracy:\", accuracy_score(y_test, y_pred_gaussian))\n",
                "print(\"Classification Report for GaussianNB:\\n\", classification_report(y_test, y_pred_gaussian))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "\n",
                "- **Train MultinomialNB**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "MultinomialNB Accuracy: 0.8156424581005587\n",
                        "Classification Report for MultinomialNB:\n",
                        "               precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.84      0.90      0.87       126\n",
                        "           1       0.73      0.60      0.66        53\n",
                        "\n",
                        "    accuracy                           0.82       179\n",
                        "   macro avg       0.79      0.75      0.77       179\n",
                        "weighted avg       0.81      0.82      0.81       179\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Initialize the MultinomialNB model\n",
                "multinomial_nb = MultinomialNB()\n",
                "\n",
                "# Train the model\n",
                "multinomial_nb.fit(X_train, y_train)\n",
                "\n",
                "# Make predictions\n",
                "y_pred_multinomial = multinomial_nb.predict(X_test)\n",
                "\n",
                "# Evaluate the model\n",
                "print(\"MultinomialNB Accuracy:\", accuracy_score(y_test, y_pred_multinomial))\n",
                "print(\"Classification Report for MultinomialNB:\\n\", classification_report(y_test, y_pred_multinomial))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "\n",
                "**3.2. COMPARE THE MODEL'S PERFORMANCE TO DETERMINE THE MOST SUITABLE ONE FOR THIS PROBLEM**\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**MODEL PERFORMANCE COMPARISON** \n",
                "\n",
                "Based on the accuracy scores of the three Naive Bayes models:\n",
                "\n",
                "- **BernoulliNB Accuracy**: 0.7709\n",
                "- **GaussianNB Accuracy**: 0.8045\n",
                "- **MultinomialNB Accuracy**: 0.8156\n",
                "\n",
                "The **`MultinomialNB`** model performs best for this problem, achieving the highest accuracy of **81.56%**. This is expected due to its design, which is optimized for text classification tasks involving word count data.\n",
                "\n",
                "The GaussianNB model, while performing decently, is more suited for continuous data rather than the discrete features we are using. The BernoulliNB model, optimized for binary features, also performed well but not as effectively as MultinomialNB for this specific problem.\n",
                "\n",
                "Hence, **`MultinomialNB` is the best choice for our sentiment analysis classifier**."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "\n",
                "<br>\n",
                "\n",
                "## **STEP 4: OPTIMIZE THE MODEL WITH RANDOM FOREST**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In Step 4, we aim to improve the performance of the MultinomialNB model (our best-performing Naive Bayes implementation) by combining it with a Random Forest Classifier. This involves:\n",
                "\n",
                "Using the predictions from the MultinomialNB model as features for the Random Forest.\n",
                "Training the Random Forest model to further refine the classification.\n",
                "Comparing the performance of the optimized model with the original Naive Bayes model to evaluate improvements.\n",
                "This step explores whether an ensemble method like Random Forest can boost the accuracy by capturing patterns that MultinomialNB might miss."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Generate Predictions from MultinomialNB**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use the best MultinomialNB model to generate predictions for train and test data\n",
                "multinomial_nb = MultinomialNB()\n",
                "multinomial_nb.fit(X_train, y_train)\n",
                "\n",
                "# Get probabilities (predictions for Random Forest)\n",
                "train_predictions_nb = multinomial_nb.predict_proba(X_train)\n",
                "test_predictions_nb = multinomial_nb.predict_proba(X_test)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Train the Random Forest**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Random Forest Accuracy: 0.8268156424581006\n",
                        "Classification Report for Random Forest:\n",
                        "               precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.87      0.88      0.88       126\n",
                        "           1       0.71      0.70      0.70        53\n",
                        "\n",
                        "    accuracy                           0.83       179\n",
                        "   macro avg       0.79      0.79      0.79       179\n",
                        "weighted avg       0.83      0.83      0.83       179\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Initialize the Random Forest Classifier\n",
                "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "\n",
                "# Train Random Forest using MultinomialNB probabilities as features\n",
                "random_forest.fit(train_predictions_nb, y_train)\n",
                "\n",
                "# Make predictions with the optimized model\n",
                "y_pred_rf = random_forest.predict(test_predictions_nb)\n",
                "\n",
                "# Evaluate the Random Forest model\n",
                "from sklearn.metrics import accuracy_score, classification_report\n",
                "\n",
                "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
                "print(\"Classification Report for Random Forest:\\n\", classification_report(y_test, y_pred_rf))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Compare Performance**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "MultinomialNB Accuracy: 0.8156424581005587\n",
                        "Random Forest Accuracy (Optimized): 0.8268156424581006\n"
                    ]
                }
            ],
            "source": [
                "# Comparing MultinomialNB and Optimized Random Forest\n",
                "print(\"MultinomialNB Accuracy:\", accuracy_score(y_test, multinomial_nb.predict(X_test)))\n",
                "print(\"Random Forest Accuracy (Optimized):\", accuracy_score(y_test, y_pred_rf))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Conclusion:**\n",
                "\n",
                "By training a Random Forest Classifier using the output of **`MultinomialNB`** as features, we can evaluate if the ensemble approach provides an improvement in accuracy or other performance metrics. If the optimized model shows better results, it validates the effectiveness of combining models for sentiment analysis."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "\n",
                "## **STEP 5: SAVE THE MODEL**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Optimized Random Forest model saved as 'random_forest_model.pkl'\n"
                    ]
                }
            ],
            "source": [
                "# Save the Optimized Random Forest Model\n",
                "with open('random_forest_model.pkl', 'wb') as model_file:\n",
                "    pickle.dump(random_forest, model_file)\n",
                "\n",
                "print(\"Optimized Random Forest model saved as 'random_forest_model.pkl'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "\n",
                "## **STEP 6: EXPLORE ALTERNATIVE MODELS**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "SVM Accuracy: 0.8324022346368715\n",
                        "Classification Report for SVM:\n",
                        "               precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.93      0.83      0.87       126\n",
                        "           1       0.67      0.85      0.75        53\n",
                        "\n",
                        "    accuracy                           0.83       179\n",
                        "   macro avg       0.80      0.84      0.81       179\n",
                        "weighted avg       0.85      0.83      0.84       179\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Initialize the SVM model\n",
                "svm_model = SVC(kernel='linear', random_state=42)\n",
                "\n",
                "# Train the model\n",
                "svm_model.fit(X_train, y_train)\n",
                "\n",
                "# Make predictions\n",
                "y_pred_svm = svm_model.predict(X_test)\n",
                "\n",
                "# Evaluate the model\n",
                "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
                "print(\"Classification Report for SVM:\\n\", classification_report(y_test, y_pred_svm))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Comparison of SVM and Random Forest Results**\n",
                "\n",
                "#### **Support Vector Machines (SVM) Results:**\n",
                "- **Accuracy**: 0.8324\n",
                "- **Precision**:\n",
                "  - Class 0: 0.93\n",
                "  - Class 1: 0.67\n",
                "- **Recall**:\n",
                "  - Class 0: 0.83\n",
                "  - Class 1: 0.85\n",
                "- **F1-Score**:\n",
                "  - Class 0: 0.87\n",
                "  - Class 1: 0.75\n",
                "- **Macro Average F1-Score**: 0.81\n",
                "- **Weighted Average F1-Score**: 0.85\n",
                "\n",
                "#### **Random Forest Results:**\n",
                "- **Accuracy**: 0.8268\n",
                "- **Precision**:\n",
                "  - Class 0: 0.87\n",
                "  - Class 1: 0.71\n",
                "- **Recall**:\n",
                "  - Class 0: 0.88\n",
                "  - Class 1: 0.70\n",
                "- **F1-Score**:\n",
                "  - Class 0: 0.88\n",
                "  - Class 1: 0.70\n",
                "- **Macro Average F1-Score**: 0.79\n",
                "- **Weighted Average F1-Score**: 0.83\n",
                "\n",
                "<br>\n",
                "\n",
                "### **Comparison:**\n",
                "1. **Accuracy**:\n",
                "   - SVM slightly outperformed Random Forest with **83.24%** vs. **82.68%**.\n",
                "\n",
                "2. **Precision**:\n",
                "   - SVM achieved a higher precision for **Class 0** (0.93 vs. 0.87), indicating fewer false positives.\n",
                "   - Random Forest had better precision for **Class 1** (0.71 vs. 0.67), showing it handled positive reviews slightly better in terms of false positives.\n",
                "\n",
                "3. **Recall**:\n",
                "   - SVM had a better recall for **Class 1** (0.85 vs. 0.70), capturing more true positives for this class.\n",
                "   - Random Forest had a slightly higher recall for **Class 0** (0.88 vs. 0.83), meaning it detected more true negatives.\n",
                "\n",
                "4. **F1-Score**:\n",
                "   - SVM had a higher F1-Score for **Class 1** (0.75 vs. 0.70), showing a better balance between precision and recall.\n",
                "   - For **Class 0**, Random Forest and SVM were very close (0.88 vs. 0.87).\n",
                "\n",
                "5. **Weighted and Macro Averages**:\n",
                "   - SVM showed better overall scores, with a **weighted average F1-Score** of **0.85** vs. **0.83** for Random Forest, and a **macro average F1-Score** of **0.81** vs. **0.79**.\n",
                "\n",
                "<br>\n",
                "\n",
                "### **Observation:**\n",
                "While both models performed well, **SVM** slightly outperformed Random Forest in terms of accuracy, recall for Class 1, and overall F1-Scores. The SVM model is particularly effective for text classification problems, leveraging its strength in high-dimensional spaces such as those generated by word count matrices.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "\n",
                "<br>\n",
                "\n",
                "# **STEP 7: CONCLUSION**\n",
                "\n",
                "#### **Overview**\n",
                "This project aimed to build a sentiment analysis classifier for Google Play Store reviews using **Naive Bayes Models** and explore alternative methods to optimize performance. Through the steps, we developed, trained, and evaluated multiple models, including **MultinomialNB**, **Random Forest**, and **Support Vector Machines (SVM)**.\n",
                "\n",
                "<br>\n",
                "\n",
                "---\n",
                "\n",
                "<br>\n",
                "\n",
                "#### **Model Comparisons**\n",
                "The performance of the models is summarized below:\n",
                "\n",
                "- **MultinomialNB**:\n",
                "  - Accuracy: **0.8156**\n",
                "  - Strength: Efficient and interpretable for text classification tasks using word count data.\n",
                "  - Limitation: Slightly lower recall for positive reviews (Class 1).\n",
                "\n",
                "- **Random Forest**:\n",
                "  - Accuracy: **0.8268**\n",
                "  - Strength: Ensemble learning improved classification balance across both classes.\n",
                "  - Limitation: Computationally more expensive and slightly less recall for positive reviews compared to SVM.\n",
                "\n",
                "- **Support Vector Machines (SVM)**:\n",
                "  - Accuracy: **0.8324**\n",
                "  - Precision:\n",
                "    - Class 0: **0.93**\n",
                "    - Class 1: **0.67**\n",
                "  - Recall:\n",
                "    - Class 0: **0.83**\n",
                "    - Class 1: **0.85**\n",
                "  - Strength: Best accuracy and recall for positive reviews (Class 1), showcasing its ability to handle high-dimensional data.\n",
                "  - Limitation: Slightly lower precision for positive reviews (Class 1).\n",
                "\n",
                "<br>\n",
                "\n",
                "---\n",
                "\n",
                "<br>\n",
                "\n",
                "#### **Key Findings**\n",
                "1. **Naive Bayes Models**:\n",
                "   - The **MultinomialNB** model performed well, leveraging its simplicity and suitability for word count data.\n",
                "   - While effective, its performance was slightly outperformed by more advanced models like SVM.\n",
                "\n",
                "2. **Alternative Models**:\n",
                "   - The **Random Forest** model provided a balanced performance but was computationally more expensive.\n",
                "   - The **SVM** model achieved the highest accuracy and overall performance, particularly excelling in identifying positive reviews.\n",
                "\n",
                "<br>\n",
                "\n",
                "---\n",
                "\n",
                "<br>\n",
                "\n",
                "#### **Final Recommendation**\n",
                "For this specific sentiment analysis task:\n",
                "- **Support Vector Machines (SVM)** is the best-performing model, offering the highest accuracy (**83.24%**) and strong recall for positive reviews. \n",
                "- However, **MultinomialNB** remains a solid choice for quick, efficient text classification tasks, especially when computational resources are limited.\n",
                "\n",
                "<br>\n",
                "\n",
                "---\n",
                "\n",
                "<br>\n",
                "\n",
                "#### **Future Work**\n",
                "1. Experiment with hyperparameter tuning for all models to further improve performance.\n",
                "2. Use more advanced text vectorization techniques, such as **TF-IDF** or **word embeddings** (e.g., Word2Vec, GloVe).\n",
                "3. Explore deep learning models (e.g., LSTM, Transformers) for sentiment analysis on larger datasets.\n",
                "\n",
                "The project demonstrates how different machine learning models can be applied to sentiment analysis, highlighting the strengths and trade-offs of each approach.\n",
                "\n",
                "<br>\n",
                "\n",
                "<br>\n",
                "\n",
                "<br>\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.6"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
